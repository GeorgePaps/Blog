<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="This essay outlines some major developments in the field of computer vision, beginning with Perceptron and progressing to more recent advances such as EfficientNet.\nPerceptron (1958)\rOur journey will start in the late 50s. In 1958 Rosenblatt [1], an erudite psychologist, conceived the earliest and simplest type of artificial neural network, the Perceptron. The Perceptron functions as a simple classifier which based on some inputs, outputs 0 or 1. Its calculations are straightforward: take the inputs, calculate their weighted average, add a parameter called bias, and check the sign of the result. If the result is greater or equal to zero the neuron outputs 1, otherwise if the result is less than 0 it outputs 0.\n">
<title>Glimpses of Computer Vision (Draft)</title>

<link rel='canonical' href='https://georgepaps.pages.dev/post/computervision1/'>

<link rel="stylesheet" href="/scss/style.min.b9c8156d464c343bdacaf14a871581fb94cbbdb9dd5cbce4ba017361187cc930.css"><meta property='og:title' content="Glimpses of Computer Vision (Draft)">
<meta property='og:description' content="This essay outlines some major developments in the field of computer vision, beginning with Perceptron and progressing to more recent advances such as EfficientNet.\nPerceptron (1958)\rOur journey will start in the late 50s. In 1958 Rosenblatt [1], an erudite psychologist, conceived the earliest and simplest type of artificial neural network, the Perceptron. The Perceptron functions as a simple classifier which based on some inputs, outputs 0 or 1. Its calculations are straightforward: take the inputs, calculate their weighted average, add a parameter called bias, and check the sign of the result. If the result is greater or equal to zero the neuron outputs 1, otherwise if the result is less than 0 it outputs 0.\n">
<meta property='og:url' content='https://georgepaps.pages.dev/post/computervision1/'>
<meta property='og:site_name' content='George Paps Blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2025-09-27T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2025-09-27T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="Glimpses of Computer Vision (Draft)">
<meta name="twitter:description" content="This essay outlines some major developments in the field of computer vision, beginning with Perceptron and progressing to more recent advances such as EfficientNet.\nPerceptron (1958)\rOur journey will start in the late 50s. In 1958 Rosenblatt [1], an erudite psychologist, conceived the earliest and simplest type of artificial neural network, the Perceptron. The Perceptron functions as a simple classifier which based on some inputs, outputs 0 or 1. Its calculations are straightforward: take the inputs, calculate their weighted average, add a parameter called bias, and check the sign of the result. If the result is greater or equal to zero the neuron outputs 1, otherwise if the result is less than 0 it outputs 0.\n">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column compact"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    <img src="/img/engin-akyurt-Hlkuojv_P6I-unsplash.jpg" width="300" height="300" class="site-logo" loading="lazy" alt="Avatar">
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">George Paps Blog</a></h1>
            <h2 class="site-description"></h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>Dark Mode</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/articles/" >
                Articles
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/post/computervision1/">Glimpses of Computer Vision (Draft)</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Sep 27, 2025</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    6 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p>This essay outlines some major developments in the field of computer vision,
beginning with Perceptron and progressing to more recent advances such as EfficientNet.</p>
<h2 id="perceptron-1958">Perceptron (1958)
</h2><p>Our journey will start in the late 50s.
In 1958 Rosenblatt [1], an erudite psychologist,
conceived the earliest and simplest type of artificial neural network, the Perceptron.
The Perceptron functions as a simple classifier
which based on some inputs, outputs 0 or 1.
Its calculations are straightforward:
take the inputs,
calculate their weighted average,
add a parameter called bias,
and check the sign of the result.
If the result is greater or equal to zero the neuron outputs 1,
otherwise if the result is less than 0 it outputs 0.</p>
<p>In mathematical notation the equation described above for four inputs is:</p>
<p>$$
z = w_{1}*x_{1} + w_{2}*x_{2} + w_{3}*x_{3} + w_{4}*x_{4} + b \
$$
$$
\text{output:}\
$$
$$
\text{if } z&gt;= 0 \to 1 \newline
\text{if } z &lt; 0 \to 0
$$
or in condensed form $z$ can be calculated as:</p>
<p>$$z=\sum_{i=1}^n w_{i}*x_i + b $$</p>
<p>The calculations Perceptron performs seem and are simple.
<strong>They key contribution of Perceptron though,
lies not in its calculations,
but on its learning algorithm.</strong></p>
<p>To get a better understanding of how Perceptron works,
let&rsquo;s start with a simple house classification problem.
We want, given the square meters, the number of rooms, the construction year,
the price, and an indicator of how expensive the area is,
to identify whether a house is a bargain or not.
Since Perceptron is a classifier
we can use it to help us identify bargains.
The problem statement mentioned above can be restated in the following way:
$$
z = w_{1}*x_{1} + w_{2}*x_{2} + w_{3}*x_{3} + w_{4}*x_{4} + w_{4}*x_{4} + b \
$$</p>
<p>$$
\text{where:}
$$</p>
<p>$$
x_{1} \text{: square meters of the house} \newline
x_{2} \text{: number of rooms} \newline
x_{3} \text{: construction year} \newline
x_{4} \text{: price} \newline
x_{5} \text{: area indicator} \newline
$$</p>
<p>Now, if $z &gt; 0$ we&rsquo;ll say that the house is a bargain, otherwise it is not.</p>
<p>In the problem statement there are five $x$ variables describing each house,
and  6 parameters $w_{1},w_{2},w_{3},w_{4},w_{5}, w_{6}$, and $b$
that affect the outcome.
These parameters,
when selected appropriately,
can result in the equation correctly identifying
whether a house is a bargain or not.
For the houses that are bargains
their weighted average plus b would be greater than zero
for the rest it will be less than zero.
But how do we decide what values these 6 parameters will take?</p>
<p>The process of picking the appropriate parameters
for our Perceptron is called <strong>training</strong>.
For the training process to take place
we need training examples,
houses with known values for the 5 variables describing them
and knowledge of whether they are a bargain or not.
Having these training examples we can tune the parameters
in order to classify a house as a bargain or not.
Without getting into many details,
here is the high level training algorithm used by Perceptron.</p>
<pre tabindex="0"><code>1) pick random values for the parameters w1,w2,w3,w4,w5,b

2) pick an example house:

    a) calculate z based on house variables and parameters
    b) if z &gt; 0 the algorithm predicts the house is a bargain, otherwise not
    c) does the prediction agree with the example?
        i) yes -&gt; continue to next example
        ii) no -&gt;  update the parameters and continue to next example
</code></pre><p>The second loop continues until we go through all examples being correctly classified
or some other stopping condition if it takes too many iteration to classify all houses correctly.</p>
<p><strong>One of the main contributions of Perceptron
is the training algorithm described in step 2.</strong>
This step-by-step learning by example process captured the imagination
of the scientist of the time.
It might felt reminiscent on some level to how we learn;
we make attempts towards our goal
and when we make a mistake we learn from it
and adjust our strategy.</p>
<h2 id="le-net-1998">Le Net (1998)
</h2><p>French machine-learning heavyweight Yann LeCun introduced in 1998 [2]
a convolutional neural network used for image classification, LeNet5.
On a high level LeNet5 shares some similar characteristics with Perceptron:
both receive inputs<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>,
perform calculations based on trainable parameters,
and classify the output<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.
LeNet5 though is a significantly more complicated artificial neural network.
The input has much bigger size
and the calculations are more complicated and consist of many successive layers.</p>
<p>The main problem networks similar to LeNet5 faced
was the significantly higher number of trainable parameters
due to bigger input size and more calculations.
To get a sense of scale,
LeNet5 has around 60.000 trainable parameters,
while the Perceptron example discussed earlier has 6.
This made training the networks very challenging.
And here lies the main contribution of LeNet5,
LeCun implemented the efficient and still widely used
method for training neural networks called backpropagation.
This development made feasible the training of networks similar to LeNet5
and contributed to their widespread adoption.</p>
<p>LeNet5 can be considered a foundational neural network for deep learning,
and has made other contributions in the field, aside of the backpropagation method.
It formalized the convolution operation with weight sharing filters,
it demonstrated that successive convolutional layers
can effectively capture spatial hierarchies,
and it also introduced the use of pooling layers.
Additionally the overall architecture introduced by LeNet5
was used as the basis for subsequent models.</p>
<h2 id="alexnet-2012">AlexNet (2012)
</h2><p>AlexNet, developed by Krizhevsky, Sutskever, and Hinton [3],
is a neural network similar to LeNet-5 but implemented on a significantly larger scale<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>, with important technical innovations and remarkable performance.
The overall network architecture is rather similar to LeNet5,
an indication of its lasting influence.</p>
<p>The main contribution of AlexNet is that it
further showcased the feasibility of using deep convolutional neural networks
for real-world computer visions tasks.
It achieved this through a rigorous technical implementation
and by using a number of technical innovations as:
(1) ReLU activation functions,
(2) parallel training in 2 GPUs,
(3) dropout regularization and creative data augmentation techniques to avoid overfitting,
and (4) overlapping max-pooling filters.</p>
<h2 id="vgg-16-2015">VGG-16 (2015)
</h2><p>&hellip;</p>
<h2 id="resnet-2015">ResNet (2015)
</h2><p>&hellip;</p>
<h2 id="references">References
</h2><p>[1] F. Rosenblatt, &ldquo;The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain,&rdquo; <em>Psychological Review</em>, vol. 65, no. 6, pp. 386–408, 1958. <a class="link" href="https://doi.org/10.1037/h0042519"  target="_blank" rel="noopener"
    >DOI: 10.1037/h0042519</a></p>
<p>[2] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, &ldquo;Gradient-based learning applied to document recognition,&rdquo; <em>Proceedings of the IEEE</em>, vol. 86, no. 11, pp. 2278–2324, 1998. <a class="link" href="https://doi.org/10.1109/5.726791"  target="_blank" rel="noopener"
    >DOI: 10.1109/5.726791</a></p>
<p>[3] A. Krizhevsky, I. Sutskever, and G. E. Hinton, &ldquo;ImageNet Classification with Deep Convolutional Neural Networks,&rdquo; <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2012. <a class="link" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"  target="_blank" rel="noopener"
    >PDF</a></p>
<p>[4] K. Simonyan and A. Zisserman, &ldquo;Very Deep Convolutional Networks for Large-Scale Image Recognition,&rdquo; arXiv preprint arXiv:1409.1556, 2014. <a class="link" href="https://arxiv.org/abs/1409.1556"  target="_blank" rel="noopener"
    >arXiv:1409.1556</a></p>
<p>[5] K. He, X. Zhang, S. Ren, and J. Sun, &ldquo;Deep Residual Learning for Image Recognition,&rdquo; <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2016. <a class="link" href="https://doi.org/10.1109/CVPR.2016.90"  target="_blank" rel="noopener"
    >DOI: 10.1109/CVPR.2016.90</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>In the case of LeNet5 the inputs are 32x32 black and white images, so the input has $32*32 = 1024$ data points for every example compared to the $5$ points for each Perceptron example.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>In the Perceptron example it classified the house as a bargain or not,
LeNet5 recognizes hand-written digits which is equivalent to classifying the images to the classes: 0,1,2,3,4,5,6,7,8,9&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>The jump in the scale of the model is impressive.
The input size increases from 32x32 black and white images to
227x227 color images,
thus from 1024 data points per example to 154.587 data points per example.
The number of trainable parameters climbs from 60 thousand to 60 million.
The number of layers increases from 7 to 12
and the network classifies the images between a 1000 categories instead of 10.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

</section>


    <footer class="article-footer">
    

    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
	const mainArticleElement = document.querySelector(".main-article");
        renderMathInElement(mainArticleElement, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>

    
</article>

    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2025 George Paps Blog
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.31.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
